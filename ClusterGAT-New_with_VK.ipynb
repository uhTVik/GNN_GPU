{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11891588",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b6917f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import time\n",
    "import metis\n",
    "import torch\n",
    "import random\n",
    "import torch_geometric\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "# Inline command\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc998a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VK DATA SET\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from torch_sparse import coalesce\n",
    "from torch_geometric.data import (InMemoryDataset, Data, download_url,\n",
    "                                  extract_zip)\n",
    "\n",
    "\n",
    "class VK(InMemoryDataset):\n",
    "\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['vk_data.npz', 'vk_graph.npz']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    # def download(self):\n",
    "    #     path = download_url(self.url, self.raw_dir)\n",
    "    #     extract_zip(path, self.raw_dir)\n",
    "    #     os.unlink(path)\n",
    "\n",
    "    def process(self):\n",
    "        data = np.load(osp.join(self.raw_dir, 'vk_data.npz'))\n",
    "        x = torch.from_numpy(data['feature']).to(torch.float)\n",
    "        y = torch.from_numpy(data['label']).to(torch.long)\n",
    "        split = torch.from_numpy(data['node_types'])\n",
    "\n",
    "        adj = sp.load_npz(osp.join(self.raw_dir, 'vk_graph.npz'))\n",
    "        row = torch.from_numpy(adj.row).to(torch.long)\n",
    "        col = torch.from_numpy(adj.col).to(torch.long)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "        edge_index, _ = coalesce(edge_index, None, x.size(0), x.size(0))\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "        data.train_mask = split == 1\n",
    "        data.val_mask = split == 2\n",
    "        data.test_mask = split == 3\n",
    "\n",
    "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "\n",
    "        torch.save(self.collate([data]), self.processed_paths[0])\n",
    "\n",
    "dataset = VK(root='./datasets/VK')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebc9baa",
   "metadata": {},
   "source": [
    "## Load Dataset using PyG Dataset Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b75e848",
   "metadata": {},
   "source": [
    "### Reddit Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3925c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset library\n",
    "from torch_geometric.datasets import Reddit\n",
    "# Download dataset\n",
    "dataset = Reddit(root='./datasets/Reddit')\n",
    "dataset.transform = T.NormalizeFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a19652",
   "metadata": {},
   "source": [
    "### Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35088ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset library\n",
    "from torch_geometric.datasets import Planetoid\n",
    "# Download dataset\n",
    "dataset = Planetoid(root='./datasets/Cora', name='Cora')\n",
    "dataset.transform = T.NormalizeFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62fb9dc",
   "metadata": {},
   "source": [
    "### Karate Club Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af00dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset library\n",
    "from torch_geometric.datasets import KarateClub\n",
    "# Download dataset\n",
    "dataset = KarateClub()\n",
    "dataset.transform = T.NormalizeFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30744ec6",
   "metadata": {},
   "source": [
    "## Dataset Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51bf7685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "===========================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n"
     ]
    }
   ],
   "source": [
    "# Print dataset information\n",
    "print('Dataset: {}'.format(dataset))\n",
    "print('===========================')\n",
    "print('Number of graphs: {}'.format(len(dataset)))\n",
    "print('Number of features: {}'.format(dataset.num_features))\n",
    "print('Number of classes: {}'.format(dataset.num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be53d9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph details\n",
      "===========================\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n",
      "Average node degree: 3.90\n",
      "Number of training nodes: 140\n",
      "Number of validation nodes: 500\n",
      "Number of test nodes: 1000\n",
      "Training node label rate: 0.05\n",
      "Contains isolated nodes: False\n",
      "Contains self loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# Print dataset detailed information\n",
    "graph_data = dataset[0]\n",
    "print('Graph details')\n",
    "print('===========================')\n",
    "print('Number of nodes: {}'.format(graph_data.num_nodes))\n",
    "print('Number of edges: {}'.format(graph_data.num_edges))\n",
    "print('Average node degree: {:.2f}'.format(graph_data.num_edges / graph_data.num_nodes))\n",
    "print('Number of training nodes: {}'.format(graph_data.train_mask.sum()))\n",
    "print('Number of validation nodes: {}'.format(graph_data.val_mask.sum()))\n",
    "print('Number of test nodes: {}'.format(graph_data.test_mask.sum()))\n",
    "print('Training node label rate: {:.2f}'.format(int(graph_data.train_mask.sum()) / graph_data.num_nodes))\n",
    "print('Contains isolated nodes: {}'.format(graph_data.has_isolated_nodes()))\n",
    "print('Contains self loops: {}'.format(graph_data.has_self_loops()))\n",
    "print('Is undirected: {}'.format(graph_data.is_undirected()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4515fc96",
   "metadata": {},
   "source": [
    "## Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ae49e2",
   "metadata": {},
   "source": [
    "### Graph Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "338fb92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphTools(object):\n",
    "    def __init__(self, graph, partition_num=10):\n",
    "        self.graph = graph\n",
    "        self.node_label = graph.y\n",
    "        self.partition_num = partition_num\n",
    "        self.node_feature_num = graph.num_node_features\n",
    "        self.graph_class_num = len(np.unique(graph.y))\n",
    "    \n",
    "    def visualize_graph(self, color=None, epoch=None, loss=None):\n",
    "        print(\"[Graph tools] Plotting graph\")\n",
    "        # Define plot properties\n",
    "        plt.figure(figsize=(7,7))\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        rgb = color if (color is not(None)) else np.random.rand(3,).reshape(1,-1) \n",
    "\n",
    "        # Check whether input is in tensor or NX graph representation\n",
    "        if (torch.is_tensor(self.graph)):\n",
    "            # Convert tensor to numpy array\n",
    "            graph_numpy = self.graph.detach().cpu().numpy()\n",
    "            # Create scatter plot\n",
    "            plt.scatter(graph_numpy[:, 0], graph_numpy[:, 0], s=140, color=rgb, cmap='Set2')\n",
    "            # Print additional label\n",
    "            if ((epoch is not None) and (loss is not None)):\n",
    "                plt.xlabel('Epoch: {}, Loss: {:.4f}'.format(epoch, loss.item()), fontsize=16)\n",
    "        else:\n",
    "            # Convert graph to networkx format\n",
    "            graph_nx = to_networkx(self.graph, to_undirected=True, node_attrs=['x'] if (self.graph.num_node_features) else None, edge_attrs=['edge_attr'] if (self.graph.num_edge_features) else None)\n",
    "            nx.draw_networkx(graph_nx, pos=nx.spring_layout(graph_nx, seed=42), with_labels=False, node_size=100, node_color=rgb, cmap='Set2')\n",
    "        \n",
    "        # Show graph\n",
    "        plt.show()\n",
    "        \n",
    "    def decompose_graph(self):\n",
    "        # Convert graph into networkX representation\n",
    "        print(\"[Graph tools] Converting graph from tensor to networkX\")\n",
    "        self.nx_graph = to_networkx(self.graph, to_undirected=True, node_attrs=['x'] if (self.graph.num_node_features) else None, edge_attrs=['edge_attr'] if (self.graph.num_edge_features) else None)\n",
    "        # Partition graph\n",
    "        print(\"[Graph tools] Partitioning graph using metis\")\n",
    "        (edgecuts, parts) = metis.part_graph(self.nx_graph, self.partition_num)\n",
    "        # Create cluster membership list\n",
    "        self.clusters = list(set(parts))\n",
    "        self.cluster_members = {node : member for node, member in enumerate(parts)}\n",
    "            \n",
    "    def generate_subgraph(self):\n",
    "        self.subgraph_nodes = {}\n",
    "        self.subgraph_edges = {}\n",
    "        self.subgraph_node_features = {}\n",
    "        self.subgraph_edge_features = {}\n",
    "        self.subgraph_node_labels = {}\n",
    "        for cluster in self.clusters:\n",
    "            subgraph = self.nx_graph.subgraph([node for node in sorted(self.nx_graph.nodes()) if (self.cluster_members[node] == cluster)])\n",
    "            self.subgraph_nodes[cluster] = [node[0] for node in sorted(subgraph.nodes(data=True))]\n",
    "            mapper = {node : i for i, node in enumerate(sorted(self.subgraph_nodes[cluster]))}\n",
    "            self.subgraph_edges[cluster] = [[mapper[edge[0]], mapper[edge[1]]] for edge in subgraph.edges()] + [[mapper[edge[1]], mapper[edge[0]]] for edge in subgraph.edges()]\n",
    "            self.subgraph_node_features[cluster] = [node[1]['x'] for node in sorted(subgraph.nodes(data=True))]\n",
    "            self.subgraph_node_labels[cluster] = self.node_label[self.subgraph_nodes[cluster]]\n",
    "            \n",
    "    def subgraph_to_tensor(self):\n",
    "        for cluster in self.clusters:\n",
    "            self.subgraph_nodes[cluster] = torch.LongTensor(self.subgraph_nodes[cluster])\n",
    "            self.subgraph_edges[cluster] = torch.LongTensor(self.subgraph_edges[cluster])\n",
    "            self.subgraph_node_features[cluster] = torch.FloatTensor(self.subgraph_node_features[cluster])\n",
    "            self.subgraph_node_labels[cluster] = torch.LongTensor(self.subgraph_node_labels[cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7d4c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Graph tools] Converting graph from tensor to networkX\n",
      "[Graph tools] Partitioning graph using metis\n"
     ]
    }
   ],
   "source": [
    "graph_tools = GraphTools(graph_data)\n",
    "# graph_tools.visualize_graph()\n",
    "graph_tools.decompose_graph()\n",
    "graph_tools.generate_subgraph()\n",
    "graph_tools.subgraph_to_tensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a2d763",
   "metadata": {},
   "source": [
    "## Graph Attention Network (GAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5816e09",
   "metadata": {},
   "source": [
    "### Define Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fad82fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAT(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, hidden_features=8, input_head=8, output_head=1):\n",
    "        # Define class properties\n",
    "        super(GAT, self).__init__()\n",
    "        self.input_channels = input_channels\n",
    "        self.output_channels = output_channels\n",
    "        self.hidden_features = hidden_features\n",
    "        self.input_head = input_head\n",
    "        self.output_head = output_head\n",
    "\n",
    "        # Define attention mechanism\n",
    "        self.attention1 = GATConv(self.input_channels, self.hidden_features, heads=self.input_head, dropout=0.6)\n",
    "        self.attention2 = GATConv((self.hidden_features*self.input_head), self.output_channels, concat=False, heads=self.output_head, dropout=0.6)\n",
    "\n",
    "    def forward(self, data):\n",
    "        # Define feedforward process\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # First layer\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.attention1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        # Second layer\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.attention2(x, edge_index)\n",
    "        # Output value\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d7f249",
   "metadata": {},
   "source": [
    "### Define Trainer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42774710",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATTrainer(object):\n",
    "    def __init__(self, graph_cluster, epochs=100, learning_rate=0.005, num_train_per_class=10):\n",
    "        # Define class properties\n",
    "        self.graph_cluster = graph_cluster\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.transform = RandomNodeSplit(split='random', num_train_per_class=num_train_per_class, num_val=0.1, num_test=0.2)\n",
    "        self.total_train_loss = 0\n",
    "        self.total_node_count = 0\n",
    "        self.create_network()\n",
    "    \n",
    "    def create_network(self):\n",
    "        self.model = GAT(self.graph_cluster.node_feature_num, self.graph_cluster.graph_class_num)\n",
    "        self.model = self.model.to(self.device)\n",
    "    \n",
    "    def update_avg_loss(self, batch_avg_loss, node_count):\n",
    "        self.total_train_loss = self.total_train_loss + batch_avg_loss.item() * node_count\n",
    "        self.total_node_count = self.total_node_count + node_count\n",
    "        average_loss = self.total_train_loss / self.total_node_count\n",
    "        return average_loss\n",
    "    \n",
    "    def inference(self, cluster):\n",
    "        cluster_data = Data(x=self.graph_cluster.subgraph_node_features[cluster], edge_index=self.graph_cluster.subgraph_edges[cluster].t().contiguous(), y=self.graph_cluster.subgraph_node_labels[cluster]).to(self.device)\n",
    "        self.transform(cluster_data)\n",
    "        prediction = self.model(cluster_data)\n",
    "        prediction = prediction[cluster_data.test_mask]\n",
    "        ground_truth = cluster_data.y[cluster_data.test_mask]\n",
    "        return prediction, ground_truth\n",
    "    \n",
    "    def forward_propagation(self, cluster):\n",
    "        cluster_data = Data(x=self.graph_cluster.subgraph_node_features[cluster], edge_index=self.graph_cluster.subgraph_edges[cluster].t().contiguous(), y=self.graph_cluster.subgraph_node_labels[cluster]).to(self.device)\n",
    "        self.transform(cluster_data)\n",
    "        prediction = self.model(cluster_data)\n",
    "        avg_loss = F.nll_loss(prediction[cluster_data.train_mask], cluster_data.y[cluster_data.train_mask])\n",
    "        node_count = cluster_data.train_mask.sum()\n",
    "        return avg_loss, node_count\n",
    "        \n",
    "    def train(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=5e-4)\n",
    "        self.model.train()\n",
    "        for epoch in tqdm_notebook(range(self.epochs), desc= 'Training progress: '):\n",
    "            random.shuffle(self.graph_cluster.clusters)\n",
    "            for cluster in self.graph_cluster.clusters:\n",
    "                self.optimizer.zero_grad()\n",
    "                batch_avg_loss, node_count = self.forward_propagation(cluster)\n",
    "                batch_avg_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                average_loss = self.update_avg_loss(batch_avg_loss, node_count)\n",
    "            \n",
    "            if (epoch % 10) == 0:\n",
    "                print(\"Epoch: {} - Average Loss: {}\".format(epoch, average_loss))\n",
    "                \n",
    "    def test(self):\n",
    "        self.predictions = []\n",
    "        self.ground_truths = []\n",
    "        self.model.eval()\n",
    "        for cluster in self.graph_cluster.clusters:\n",
    "            prediction, ground_truth = self.inference(cluster)\n",
    "            self.predictions.append(prediction.cpu().detach().numpy())\n",
    "            self.ground_truths.append(ground_truth.cpu().detach().numpy())\n",
    "        self.predictions = np.concatenate(self.predictions).argmax(1)\n",
    "        self.ground_truths = np.concatenate(self.ground_truths)\n",
    "        model_score = f1_score(self.ground_truths, self.predictions, average='micro')\n",
    "        print(\"F1-score: {}\\n\".format(model_score))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb93a52",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e4d788a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2631ba6d995a4ca68d654f9b89907eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training progress:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Average Loss: 1.9419031143188477\n",
      "Epoch: 10 - Average Loss: 1.83107590675354\n",
      "Epoch: 20 - Average Loss: 1.7063993215560913\n",
      "Epoch: 30 - Average Loss: 1.6120610237121582\n",
      "Epoch: 40 - Average Loss: 1.539084553718567\n",
      "Epoch: 50 - Average Loss: 1.483109951019287\n",
      "Epoch: 60 - Average Loss: 1.442809820175171\n",
      "Epoch: 70 - Average Loss: 1.4083218574523926\n",
      "Epoch: 80 - Average Loss: 1.379614233970642\n",
      "Epoch: 90 - Average Loss: 1.3556207418441772\n",
      "Epoch: 100 - Average Loss: 1.3356729745864868\n",
      "Epoch: 110 - Average Loss: 1.319382905960083\n",
      "Epoch: 120 - Average Loss: 1.307982325553894\n",
      "Epoch: 130 - Average Loss: 1.2965439558029175\n",
      "Epoch: 140 - Average Loss: 1.2863901853561401\n",
      "Epoch: 150 - Average Loss: 1.27568519115448\n",
      "Epoch: 160 - Average Loss: 1.2673760652542114\n",
      "Epoch: 170 - Average Loss: 1.259655475616455\n",
      "Epoch: 180 - Average Loss: 1.2528756856918335\n",
      "Epoch: 190 - Average Loss: 1.2478652000427246\n",
      "Epoch: 200 - Average Loss: 1.2436083555221558\n",
      "Epoch: 210 - Average Loss: 1.2387456893920898\n",
      "Epoch: 220 - Average Loss: 1.2338026762008667\n",
      "Epoch: 230 - Average Loss: 1.228926181793213\n",
      "Epoch: 240 - Average Loss: 1.2247843742370605\n",
      "Epoch: 250 - Average Loss: 1.2200086116790771\n",
      "Epoch: 260 - Average Loss: 1.2165685892105103\n",
      "Epoch: 270 - Average Loss: 1.2130205631256104\n",
      "Epoch: 280 - Average Loss: 1.2101491689682007\n",
      "Epoch: 290 - Average Loss: 1.20693039894104\n",
      "Epoch: 300 - Average Loss: 1.20396089553833\n",
      "Epoch: 310 - Average Loss: 1.2012938261032104\n",
      "Epoch: 320 - Average Loss: 1.1991181373596191\n",
      "Epoch: 330 - Average Loss: 1.1974139213562012\n",
      "Epoch: 340 - Average Loss: 1.1945836544036865\n",
      "Epoch: 350 - Average Loss: 1.1923986673355103\n",
      "Epoch: 360 - Average Loss: 1.190609335899353\n",
      "Epoch: 370 - Average Loss: 1.1889280080795288\n",
      "Epoch: 380 - Average Loss: 1.187287449836731\n",
      "Epoch: 390 - Average Loss: 1.185340166091919\n",
      "Epoch: 400 - Average Loss: 1.1841613054275513\n",
      "Epoch: 410 - Average Loss: 1.1821796894073486\n",
      "Epoch: 420 - Average Loss: 1.18094003200531\n",
      "Epoch: 430 - Average Loss: 1.1796008348464966\n",
      "Epoch: 440 - Average Loss: 1.1784541606903076\n",
      "Epoch: 450 - Average Loss: 1.1775826215744019\n",
      "Epoch: 460 - Average Loss: 1.1764267683029175\n",
      "Epoch: 470 - Average Loss: 1.1749122142791748\n",
      "Epoch: 480 - Average Loss: 1.1737415790557861\n",
      "Epoch: 490 - Average Loss: 1.1724448204040527\n",
      "Epoch: 500 - Average Loss: 1.1712465286254883\n",
      "Epoch: 510 - Average Loss: 1.1702502965927124\n",
      "Epoch: 520 - Average Loss: 1.1691752672195435\n",
      "Epoch: 530 - Average Loss: 1.1684178113937378\n",
      "Epoch: 540 - Average Loss: 1.1678181886672974\n",
      "Epoch: 550 - Average Loss: 1.166906714439392\n",
      "Epoch: 560 - Average Loss: 1.1662018299102783\n",
      "Epoch: 570 - Average Loss: 1.1653249263763428\n",
      "Epoch: 580 - Average Loss: 1.1646686792373657\n",
      "Epoch: 590 - Average Loss: 1.163611888885498\n",
      "Epoch: 600 - Average Loss: 1.1627197265625\n",
      "Epoch: 610 - Average Loss: 1.162023663520813\n",
      "Epoch: 620 - Average Loss: 1.161433219909668\n",
      "Epoch: 630 - Average Loss: 1.161002278327942\n",
      "Epoch: 640 - Average Loss: 1.1602541208267212\n",
      "Epoch: 650 - Average Loss: 1.1594675779342651\n",
      "Epoch: 660 - Average Loss: 1.1587512493133545\n",
      "Epoch: 670 - Average Loss: 1.1581342220306396\n",
      "Epoch: 680 - Average Loss: 1.1574889421463013\n",
      "Epoch: 690 - Average Loss: 1.1570265293121338\n",
      "Epoch: 700 - Average Loss: 1.1565722227096558\n",
      "Epoch: 710 - Average Loss: 1.1560322046279907\n",
      "Epoch: 720 - Average Loss: 1.155507206916809\n",
      "Epoch: 730 - Average Loss: 1.154917597770691\n",
      "Epoch: 740 - Average Loss: 1.1543960571289062\n",
      "Epoch: 750 - Average Loss: 1.153883695602417\n",
      "Epoch: 760 - Average Loss: 1.1531578302383423\n",
      "Epoch: 770 - Average Loss: 1.1527677774429321\n",
      "Epoch: 780 - Average Loss: 1.1523876190185547\n",
      "Epoch: 790 - Average Loss: 1.1520847082138062\n",
      "Epoch: 800 - Average Loss: 1.1516578197479248\n",
      "Epoch: 810 - Average Loss: 1.1512680053710938\n",
      "Epoch: 820 - Average Loss: 1.1508787870407104\n",
      "Epoch: 830 - Average Loss: 1.1504526138305664\n",
      "Epoch: 840 - Average Loss: 1.1501494646072388\n",
      "Epoch: 850 - Average Loss: 1.1498315334320068\n",
      "Epoch: 860 - Average Loss: 1.1495862007141113\n",
      "Epoch: 870 - Average Loss: 1.1491727828979492\n",
      "Epoch: 880 - Average Loss: 1.148703694343567\n",
      "Epoch: 890 - Average Loss: 1.1485450267791748\n",
      "Epoch: 900 - Average Loss: 1.1481608152389526\n",
      "Epoch: 910 - Average Loss: 1.1475273370742798\n",
      "Epoch: 920 - Average Loss: 1.1472132205963135\n",
      "Epoch: 930 - Average Loss: 1.1469943523406982\n",
      "Epoch: 940 - Average Loss: 1.146833896636963\n",
      "Epoch: 950 - Average Loss: 1.146762728691101\n",
      "Epoch: 960 - Average Loss: 1.1462576389312744\n",
      "Epoch: 970 - Average Loss: 1.146018147468567\n",
      "Epoch: 980 - Average Loss: 1.145836591720581\n",
      "Epoch: 990 - Average Loss: 1.1456265449523926\n",
      "F1-score: 0.8722222222222223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gat_trainer = GATTrainer(graph_tools, epochs=1000)\n",
    "gat_trainer.train()\n",
    "gat_trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07adc498",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f45d111",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2fdc4f",
   "metadata": {},
   "source": [
    "## Model Playground"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e848f700",
   "metadata": {},
   "source": [
    "### Subgraph Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e58b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_subgraph = Data(x=graph_tools.subgraph_node_features[0], edge_index=graph_tools.subgraph_edges[0].t().contiguous(), y=graph_tools.subgraph_node_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd55a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Graph details')\n",
    "print('===========================')\n",
    "print('Number of nodes: {}'.format(new_subgraph.num_nodes))\n",
    "print('Number of edges: {}'.format(new_subgraph.num_edges))\n",
    "print('Number of node features: {}'.format(new_subgraph.num_node_features))\n",
    "print('Number of edge features: {}'.format(new_subgraph.num_edge_features))\n",
    "print('Number of node labels: {}'.format(len(new_subgraph.y)))\n",
    "print('Average node degree: {:.2f}'.format(new_subgraph.num_edges / new_subgraph.num_nodes))\n",
    "print('Contains isolated nodes: {}'.format(new_subgraph.has_isolated_nodes()))\n",
    "print('Contains self loops: {}'.format(new_subgraph.has_self_loops()))\n",
    "print('Is undirected: {}'.format(new_subgraph.is_undirected()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f509b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_tools = GraphTools(new_subgraph)\n",
    "subgraph_tools.visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac0361",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = RandomNodeSplit(split='random', num_train_per_class=2000, num_val=0.1, num_test=0.2)\n",
    "transform(new_subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d4a4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Graph details')\n",
    "print('===========================')\n",
    "print('Number of nodes: {}'.format(new_subgraph.num_nodes))\n",
    "print('Number of edges: {}'.format(new_subgraph.num_edges))\n",
    "print('Number of node features: {}'.format(new_subgraph.num_node_features))\n",
    "print('Number of edge features: {}'.format(new_subgraph.num_edge_features))\n",
    "print('Average node degree: {:.2f}'.format(new_subgraph.num_edges / new_subgraph.num_nodes))\n",
    "print('Number of training nodes: {}'.format(new_subgraph.train_mask.sum()))\n",
    "print('Training node label rate: {:.2f}'.format(int(new_subgraph.train_mask.sum()) / new_subgraph.num_nodes))\n",
    "print('Contains isolated nodes: {}'.format(new_subgraph.has_isolated_nodes()))\n",
    "print('Contains self loops: {}'.format(new_subgraph.has_self_loops()))\n",
    "print('Is undirected: {}'.format(new_subgraph.is_undirected()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4149fb1",
   "metadata": {},
   "source": [
    "### Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e00d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure GPU for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "# Initialize model and dataset\n",
    "model = GAT().to(device)\n",
    "data = new_subgraph.to(device)\n",
    "\n",
    "# Define training parameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "epochs  = 1000\n",
    "\n",
    "# Start training process\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "\n",
    "    if (epoch % 10) == 0:\n",
    "        print(\"Epoch: {} - Loss: {}\".format(epoch, loss))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caa8bf2",
   "metadata": {},
   "source": [
    "### Evaluation Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ea462",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float(pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f372f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
